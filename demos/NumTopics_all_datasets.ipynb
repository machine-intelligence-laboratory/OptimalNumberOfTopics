{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumTopics: all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')  # develop topicnet\n",
    "sys.path.insert(0, '..')     # topnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine.models import TopicModel\n",
    "from topicnet.cooking_machine.dataset import Dataset\n",
    "\n",
    "from topnum.data.vowpal_wabbit_text_collection import VowpalWabbitTextCollection\n",
    "from topnum.search_methods.optimize_scores_method import OptimizeScoresMethod\n",
    "from topnum.utils import (\n",
    "    read_corpus_config, split_into_train_test, \n",
    "    build_every_score, monotonity_and_std_analysis, \n",
    "    trim_config, plot_everything_informative\n",
    ")\n",
    "from topnum.model_constructor import KnownModel, PARAMS_EXPLORED\n",
    "from topnum.utils import estimate_num_iterations_for_convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NewsGroups ../topnum/configs/20NG.yml\n",
      "RuWikiGood ../topnum/configs/ruwikigood.yml\n",
      "StackOverflow ../topnum/configs/SO.yml\n",
      "WikiRef220 ../topnum/configs/WikiRef220.yml\n",
      "PostNauka ../topnum/configs/PN.yml\n",
      "Reuters ../topnum/configs/Reuters.yml\n",
      "Brown ../topnum/configs/Brown.yml\n"
     ]
    }
   ],
   "source": [
    "configs_dir = os.path.join('..', 'topnum', 'configs')\n",
    "configs_mask = os.path.join(configs_dir, '*.yml')\n",
    "\n",
    "\n",
    "for config_file in glob.glob(configs_mask):\n",
    "    config = read_corpus_config(config_file)\n",
    "\n",
    "    print(config['name'], config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with Natural order of words (if possible)!\n",
    "\n",
    "config = read_corpus_config(os.path.join(configs_dir, 'WikiRef220.yml'))\n",
    "\n",
    "# For debug\n",
    "\n",
    "config['num_restarts'] = 1\n",
    "config['num_fit_iterations'] = 5\n",
    "config['num_topics_interval'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'WikiRef220'),\n",
       "             ('dataset_path',\n",
       "              '/data_mil/datasets/WikiRef220/wiki_ref220_natural_order.csv'),\n",
       "             ('batches_prefix', 'WRef'),\n",
       "             ('word', '@lemmatized'),\n",
       "             ('min_num_topics', 2),\n",
       "             ('max_num_topics', 20),\n",
       "             ('num_topics_interval', 5),\n",
       "             ('num_fit_iterations', 5),\n",
       "             ('num_restarts', 1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(\n",
    "    '/', 'data', 'datasets', 'WikiRef220', 'wiki_ref220_natural_order.csv'\n",
    ")\n",
    "\n",
    "assert os.path.isfile(DATASET_PATH)\n",
    "\n",
    "config['dataset_path'] = DATASET_PATH\n",
    "\n",
    "DATASET_INTERNALS_FOLDER_PATH = os.path.join(\n",
    "    '.', f'{config[\"batches_prefix\"]}__internals'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    data_path=DATASET_PATH, \n",
    "    internals_folder_path=DATASET_INTERNALS_FOLDER_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_dataset, test_dataset = split_into_train_test(dataset, config)\n",
    "\n",
    "for d in [train_dataset, test_dataset]:\n",
    "    d._cached_dict = d.get_dictionary().filter(min_df_rate=MIN_DF_RATE, min_df=2)\n",
    "\n",
    "    #for modality in d.get_possible_modalities():\n",
    "    #    if modality != config['word']:\n",
    "    #        d._cached_dict.filter(class_id=modality, max_df=0, inplace=True)\n",
    "\n",
    "    #dict_path = os.path.join(d._internals_folder_path, 'dict.dict')\n",
    "    #os.remove(dict_path)\n",
    "    #d._cached_dict.save(dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_collection = VowpalWabbitTextCollection.from_dataset(\n",
    "    train_dataset,\n",
    "    main_modality=config['word'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.Dictionary(name=ea5924d9-df5e-4f73-b2a1-515edfb12307, num_entries=6148)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_collection._to_dataset().get_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf $EXPERIMENT_DIRECTORY/WRef_test_TARTM_0_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf $EXPERIMENT_DIRECTORY/WRef_test_decorrelation_0_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.LDA\n",
      "(['prior', 'symmetric'],)\n",
      "{'prior': 'symmetric'}\n",
      "skipping WRef_test_LDA_0...\n",
      "(['prior', 'asymmetric'],)\n",
      "{'prior': 'asymmetric'}\n",
      "skipping WRef_test_LDA_1...\n",
      "(['prior', 'heuristic'],)\n",
      "{'prior': 'heuristic'}\n",
      "skipping WRef_test_LDA_2...\n",
      "KnownModel.PLSA\n",
      "()\n",
      "{}\n",
      "skipping WRef_test_PLSA_0...\n",
      "KnownModel.SPARSE\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.05])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05}\n",
      "skipping WRef_test_sparse_0...\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.1])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1}\n",
      "skipping WRef_test_sparse_1...\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.05])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05}\n",
      "skipping WRef_test_sparse_2...\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.1])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1}\n",
      "skipping WRef_test_sparse_3...\n",
      "KnownModel.TLESS\n",
      "()\n",
      "{}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:43<00:00, 103.02s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.TLESS 0.028642453087700737\n",
      "KnownModel.DECORRELATION\n",
      "(['decorrelation_tau', 0.02],)\n",
      "{'decorrelation_tau': 0.02}\n",
      "skipping WRef_test_decorrelation_0...\n",
      "(['decorrelation_tau', 0.05],)\n",
      "{'decorrelation_tau': 0.05}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:36<00:00, 96.39s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.DECORRELATION 0.026823001239034864\n",
      "(['decorrelation_tau', 0.1],)\n",
      "{'decorrelation_tau': 0.1}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:35<00:00, 95.84s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.DECORRELATION 0.0266510374016232\n",
      "KnownModel.ARTM\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.05], ['decorrelation_tau', 0.02])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.02}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:38<00:00, 98.07s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.02727388898531596\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.05], ['decorrelation_tau', 0.05])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.05}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:42<00:00, 102.29s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.028442016111479864\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.05], ['decorrelation_tau', 0.1])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.1}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:41<00:00, 101.91s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.02833658708466424\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.1], ['decorrelation_tau', 0.02])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.02}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:40<00:00, 100.14s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.027844164437717863\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.1], ['decorrelation_tau', 0.05])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.05}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:42<00:00, 102.29s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.028439755903349982\n",
      "(['smooth_bcg_tau', 0.05], ['sparse_sp_tau', -0.1], ['decorrelation_tau', 0.1])\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.1}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:43<00:00, 103.08s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.028666461176342434\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.05], ['decorrelation_tau', 0.02])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.02}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:41<00:00, 101.79s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.028301187886132135\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.05], ['decorrelation_tau', 0.05])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.05}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:42<00:00, 102.03s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.028366706437534757\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.05], ['decorrelation_tau', 0.1])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.1}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:36<00:00, 96.37s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.026801313161849975\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.1], ['decorrelation_tau', 0.02])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.02}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:42<00:00, 102.64s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.02853917333814833\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.1], ['decorrelation_tau', 0.05])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.05}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:46<00:00, 106.47s/it]\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.029601087503963047\n",
      "(['smooth_bcg_tau', 0.1], ['sparse_sp_tau', -0.1], ['decorrelation_tau', 0.1])\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.1}\n",
      "Num documents for coherence: 43, 24274 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:45<00:00, 105.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnownModel.ARTM 0.029353886180453828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/data/mytopicnet/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1113: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME_TEMPLATE = f\"{config['batches_prefix']}_test\" + '_{}_{}'\n",
    "EXPERIMENT_DIRECTORY = os.path.join(\n",
    "    '/', 'data', '_tmp_bulatov', f\"{config['batches_prefix']}\"\n",
    ")\n",
    "ONE_MODEL_NUM_PROCESSORS = 3\n",
    "\n",
    "\n",
    "for model_family in KnownModel:\n",
    "    template = PARAMS_EXPLORED[model_family]\n",
    "\n",
    "    the_grid = [\n",
    "        [[key, one_value] for one_value in template[key]]\n",
    "        for key, params in template.items()\n",
    "    ]\n",
    "    \n",
    "    print(model_family)\n",
    "    \n",
    "    for idx, model_params in enumerate(itertools.product(*the_grid)):\n",
    "\n",
    "        print(model_params)\n",
    "        \n",
    "        lst = [x for x in zip(*model_params)]\n",
    "\n",
    "        if len(lst):\n",
    "            model_params = dict(zip(lst[0], lst[1]))\n",
    "        else: \n",
    "            model_params = {}\n",
    "        \n",
    "        print(model_params)\n",
    "        \n",
    "        experiment_name = EXPERIMENT_NAME_TEMPLATE.format(model_family.value, idx)\n",
    "        if os.path.isdir(EXPERIMENT_DIRECTORY + \"/\" + experiment_name + \"_0\"):\n",
    "            print(f\"skipping {experiment_name}...\")\n",
    "            continue\n",
    "\n",
    "        built_scores = build_every_score(train_dataset, test_dataset, config)\n",
    "        optimizer = OptimizeScoresMethod(\n",
    "            scores=built_scores,\n",
    "            model_family=model_family,\n",
    "            experiment_name=experiment_name,\n",
    "            experiment_directory=EXPERIMENT_DIRECTORY,\n",
    "            one_model_num_processors=ONE_MODEL_NUM_PROCESSORS,\n",
    "            model_params=model_params,\n",
    "            **trim_config(config, OptimizeScoresMethod)\n",
    "        )\n",
    "        \n",
    "        t_start = time.time()\n",
    "\n",
    "        optimizer.search_for_optimum(text_collection)\n",
    "        \n",
    "        t_end = time.time()\n",
    "        \n",
    "        print(model_family, (t_end - t_start) / 60 / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_models_mask = os.path.join(\n",
    "    EXPERIMENT_DIRECTORY,\n",
    "    EXPERIMENT_NAME_TEMPLATE.format(\"*\", \"*\"),\n",
    "    \"*\",\n",
    ")\n",
    "\n",
    "num_models_to_load = 5\n",
    "\n",
    "for entry in glob.glob(all_models_mask)[:num_models_to_load]:\n",
    "    print(entry)\n",
    "    \n",
    "    tm = TopicModel.load(entry)\n",
    "    num_iters = estimate_num_iterations_for_convergence(tm)\n",
    "    \n",
    "    print(\n",
    "        f'Num topics: {len(tm.topic_names):3}. Num iters for convergence: {num_iters:3}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonity_and_std_analysis(\n",
    "    experiment_name_template=EXPERIMENT_NAME_TEMPLATE,\n",
    "    experiment_directory=EXPERIMENT_DIRECTORY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_everything_informative(\n",
    "    EXPERIMENT_DIRECTORY, EXPERIMENT_NAME_TEMPLATE, [\"diversity\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_everything_informative(\n",
    "    EXPERIMENT_DIRECTORY, EXPERIMENT_NAME_TEMPLATE, [\"_sparsity\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_everything_informative(EXPERIMENT_DIRECTORY, EXPERIMENT_NAME_TEMPLATE, ['renyi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_everything_informative(EXPERIMENT_DIRECTORY, EXPERIMENT_NAME_TEMPLATE, ['arun'])\n",
    "plot_everything_informative(EXPERIMENT_DIRECTORY, EXPERIMENT_NAME_TEMPLATE, ['calhar'])\n",
    "plot_everything_informative(EXPERIMENT_DIRECTORY, EXPERIMENT_NAME_TEMPLATE, ['silh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_everything_informative(\n",
    "    EXPERIMENT_DIRECTORY, EXPERIMENT_NAME_TEMPLATE,\n",
    "    [], \n",
    "    [\"diversity\", \"_sparsity\", 'renyi', 'arun', 'calhar', 'silh']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mytopicnet)",
   "language": "python",
   "name": "conda_mytopicnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
