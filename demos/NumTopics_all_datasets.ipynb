{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumTopics: all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')\n",
    "from topicnet.cooking_machine.models import TopicModel\n",
    "from topicnet.cooking_machine.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from topnum.data.vowpal_wabbit_text_collection import VowpalWabbitTextCollection\n",
    "from topnum.search_methods.optimize_scores_method import OptimizeScoresMethod\n",
    "\n",
    "from topnum.utils import (\n",
    "    read_corpus_config, split_into_train_test, \n",
    "    build_every_score, monotonity_and_std_analysis, \n",
    "    trim_config, plot_everything_informative\n",
    ")\n",
    "\n",
    "\n",
    "from topnum.model_constructor import KnownModel, PARAMS_EXPLORED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackOverflow 6\n",
      "895621\n",
      "RuWikiGood 4\n",
      "8603\n",
      "Brown 6\n",
      "89830\n",
      "Reuters 6\n",
      "202715\n",
      "WikiRef220 6\n",
      "221\n",
      "PostNauka 6\n",
      "102428\n",
      "20NewsGroups 6\n",
      "616191\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "configs_dir = os.path.join('..', 'topnum', 'configs')\n",
    "configs_mask = os.path.join(configs_dir, '*.yml')\n",
    "\n",
    "\n",
    "for config_file in glob.glob(configs_mask):\n",
    "    config = read_corpus_config(config_file)\n",
    "    print(config['name'], config['num_restarts'])\n",
    "    numlines = 0\n",
    "    with open(config['dataset_path'], 'r') as f:\n",
    "        for line in f:\n",
    "            numlines += 1\n",
    "    print(numlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', '20NewsGroups'),\n",
       "             ('batches_prefix', '20NG'),\n",
       "             ('dataset_path', '/data/datasets/20_News_dataset/20NG_BOW.csv'),\n",
       "             ('word', '@word'),\n",
       "             ('min_num_topics', 10),\n",
       "             ('max_num_topics', 30),\n",
       "             ('num_topics_interval', 3),\n",
       "             ('num_fit_iterations', 40),\n",
       "             ('num_restarts', 6)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG.yml   PN.yml\truwikigood.yml\tWikiRef220.yml\r\n",
      "Brown.yml  Reuters.yml\tSO.yml\r\n"
     ]
    }
   ],
   "source": [
    "!ls $configs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug\n",
    "\n",
    "config = read_corpus_config(configs_dir + \"/ruwikigood.yml\")\n",
    "\n",
    "config['num_restarts'] = 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    config['dataset_path'], \n",
    "    internals_folder_path=f'/home/vbulatov/Projects/OptimalNumberOfTopics/demos/{config[\"batches_prefix\"]}_internals'\n",
    ")\n",
    "\n",
    "train_dataset, test_dataset = split_into_train_test(dataset, config)\n",
    "\n",
    "text_collection = VowpalWabbitTextCollection.from_dataset(train_dataset, main_modality=config['word'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prior': 'symmetric'}\n",
      "{'prior': 'asymmetric'}\n",
      "{'prior': 'small'}\n",
      "{'prior': 'heuristic'}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1}\n",
      "{'decorrelation_tau': 0.02}\n",
      "{'decorrelation_tau': 0.05}\n",
      "{'decorrelation_tau': 0.1}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.02}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.05}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.1}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.02}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.05}\n",
      "{'smooth_bcg_tau': 0.05, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.1}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.02}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.05}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.05, 'decorrelation_tau': 0.1}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.02}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.05}\n",
      "{'smooth_bcg_tau': 0.1, 'sparse_sp_tau': -0.1, 'decorrelation_tau': 0.1}\n"
     ]
    }
   ],
   "source": [
    "for model_family in KnownModel:\n",
    "    template = PARAMS_EXPLORED[model_family]\n",
    "\n",
    "    the_grid = [\n",
    "            [[key, one_value] for one_value in template[key]]\n",
    "            for key, params in template.items()\n",
    "    ]\n",
    "    for idx, model_params in enumerate(itertools.product(*the_grid)):\n",
    "        # print(dict(zip(*model_params)))\n",
    "        lst = list(x for x in zip(*model_params))\n",
    "        if len(lst):\n",
    "            model_params = dict(zip(lst[0], lst[1]))\n",
    "            print(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prior': 'symmetric'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [27:14:40<54:29:21, 98080.75s/it]"
     ]
    }
   ],
   "source": [
    "experiment_name_template = \"num_topics_{}_{}\"\n",
    "experiment_directory=f\"/data_mil/vbulatov/{config['batches_prefix']}_test1\"\n",
    "\n",
    "for model_family in KnownModel:\n",
    "    template = PARAMS_EXPLORED[model_family]\n",
    "\n",
    "    the_grid = [\n",
    "            [[key, one_value] for one_value in template[key]]\n",
    "            for key, params in template.items()\n",
    "    ]\n",
    "    for idx, model_params in enumerate(itertools.product(*the_grid)):\n",
    "        lst = [x for x in zip(*model_params)]\n",
    "        if len(lst):\n",
    "            model_params = dict(zip(lst[0], lst[1]))\n",
    "            print(model_params)\n",
    "        else: \n",
    "            model_params = {}\n",
    "        experiment_name = experiment_name_template.format(model_family.value, idx)\n",
    "        optimizer = OptimizeScoresMethod(\n",
    "            scores=build_every_score(train_dataset, test_dataset, config),\n",
    "            model_family=model_family,\n",
    "            experiment_name=experiment_name,\n",
    "            experiment_directory=experiment_directory,\n",
    "            one_model_num_processors=6,\n",
    "            **trim_config(config, OptimizeScoresMethod)\n",
    "        )\n",
    "        t_start = time.time()\n",
    "\n",
    "        optimizer.search_for_optimum(text_collection)\n",
    "        t_end = time.time()\n",
    "        print(model_family, (t_end - t_start) / 60 / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_EXPLORED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_models_mask = os.path.join(experiment_directory, experiment_name_template.format(\"*\"), \"*\")\n",
    "\n",
    "for entry in glob.glob(all_models_mask):\n",
    "    print(entry)\n",
    "    tm = TopicModel.load(entry)\n",
    "    print(len(tm.topic_names), estimate_num_iterations_for_convergence(tm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonity_and_std_analysis(\n",
    "    experiment_name_template=experiment_name_template,\n",
    "    experiment_directory=experiment_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_everything_informative(experiment_directory, experiment_name_template, [\"diversity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_everything_informative(experiment_directory, experiment_name_template, [\"_sparsity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_everything_informative(experiment_directory, experiment_name_template, ['renyi'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_everything_informative(experiment_directory, experiment_name_template, ['arun'])\n",
    "plot_everything_informative(experiment_directory, experiment_name_template, ['calhar'])\n",
    "plot_everything_informative(experiment_directory, experiment_name_template, ['silh'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_everything_informative(experiment_directory, experiment_name_template, [], \n",
    "                            [\"diversity\", \"_sparsity\", 'renyi', 'arun', 'calhar', 'silh'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
