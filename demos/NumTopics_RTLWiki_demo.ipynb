{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumTopics: RTLWiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from topicnet.cooking_machine.dataset import Dataset\n",
    "from topicnet.cooking_machine.models import TopicModel\n",
    "from topicnet.cooking_machine.model_constructor import init_simple_default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from run_search import (\n",
    "    _optimize_scores,\n",
    ")\n",
    "\n",
    "from topnum.data.vowpal_wabbit_text_collection import VowpalWabbitTextCollection\n",
    "from topnum.scores import (\n",
    "    PerplexityScore,\n",
    "    EntropyScore\n",
    ")\n",
    "from topnum.search_methods.optimize_scores_method import OptimizeScoresMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topnum.model_constructor import init_bcg_sparse_model, init_decorrelated_PLSA, init_LDA, init_PLSA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKB10.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ~/Projects/tmp_notebooks | grep csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@letter', '@ngram', '@text'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/home/vbulatov/Projects/tmp_notebooks/MKB10.csv'\n",
    "BATCHES = './MKB_batches'\n",
    "\n",
    "dataset = Dataset(PATH, batch_vectorizer_path=BATCHES)\n",
    "dataset.get_possible_modalities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = {\n",
    "    \"@text\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw_file_path = \"MKB_vw.txt\"\n",
    "\n",
    "dataset.write_vw(vw_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: instead of modalities let's use predefined model families\n",
    "# TODO: output_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_modality_name, modalities = \"@lemmatized\", modalities\n",
    "\n",
    "modality_names = list(modalities.keys())\n",
    "\n",
    "# vw_file_path = args.vw_file_path\n",
    "\n",
    "output_file_path = \"output.json\"\n",
    "\n",
    "min_num_topics = 13\n",
    "max_num_topics = 25\n",
    "\n",
    "num_topics_interval = 1\n",
    "num_fit_iterations = 10\n",
    "num_restarts = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_factor = 1\n",
    "\n",
    "scores = [EntropyScore('res', class_ids=modality_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_collection = VowpalWabbitTextCollection(\n",
    "    vw_file_path,\n",
    "    main_modality=main_modality_name,\n",
    "    modalities=modalities\n",
    ")\n",
    "\n",
    "optimizer = OptimizeScoresMethod(\n",
    "    scores=scores,\n",
    "    min_num_topics=min_num_topics,\n",
    "    max_num_topics=max_num_topics,\n",
    "    num_topics_interval=num_topics_interval,\n",
    "    num_fit_iterations=num_fit_iterations,\n",
    "    num_restarts=num_restarts,\n",
    "    # experiment_name=\"num_topics_search_10iters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "optimizer.search_for_optimum(text_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls  num_topics_experiments/e68cc1ff_experiment_-1 -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = time.time()\n",
    "\n",
    "t_end - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_result = optimizer._detailed_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower the entropy, the better is supposed to be the result model.\n",
    "On X axis is the number of topics, on Y axis â€” the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(detailed_result['renyi_entropy_score'].T)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(detailed_result['renyi_entropy_score'].T.mean(axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(detailed_result['renyi_entropy_score'].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(detailed_result['renyi_entropy_score'].T.mean(axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"detailed_result_rtl.p\", \"wb\") as f:\n",
    "    pickle.dump(detailed_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del optimizer\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models are saved and can be restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TopicModel.load(\n",
    "    \"./num_topics_experiments/e68cc1ff_experiment_-1/##13h32m50s_20d02m2020y###\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum().sum() / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean().mean() * 25/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 25\n",
    "2/(T * (T - 1)) * sum(condensed_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
