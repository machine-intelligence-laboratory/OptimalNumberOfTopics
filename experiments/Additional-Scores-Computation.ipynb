{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Scores Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')  # develop topicnet\n",
    "sys.path.insert(0, '..')     # topnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine.models import TopicModel\n",
    "from topicnet.cooking_machine.dataset import Dataset\n",
    "from topicnet.cooking_machine.models import scores as tn_scores\n",
    "from topicnet.cooking_machine.models.base_score import BaseScore as BaseTopicNetScore\n",
    "\n",
    "from topnum.data.vowpal_wabbit_text_collection import VowpalWabbitTextCollection\n",
    "from topnum.search_methods.optimize_scores_method import OptimizeScoresMethod\n",
    "from topnum.utils import (\n",
    "    read_corpus_config, split_into_train_test, \n",
    "    build_every_score, monotonity_and_std_analysis, \n",
    "    trim_config, plot_everything_informative\n",
    ")\n",
    "from topnum.model_constructor import KnownModel, PARAMS_EXPLORED\n",
    "from topnum.scores import (\n",
    "    HoldoutPerplexityScore,\n",
    "    MeanLiftScore,\n",
    "    UniformThetaDivergenceScore,\n",
    ")\n",
    "from topnum.scores.base_score import BaseScore\n",
    "from topnum.utils import estimate_num_iterations_for_convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building All Custom Scores (Auxiliary Step). Initializing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dir = os.path.join('..', 'topnum', 'configs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG.yml   PN.yml\truwikigood.yml\tWikiRef220.yml\r\n",
      "Brown.yml  Reuters.yml\tSO.yml\r\n"
     ]
    }
   ],
   "source": [
    "! ls $configs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_corpus_config(configs_dir + \"/PN.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'PostNauka'),\n",
       "             ('batches_prefix', 'PN'),\n",
       "             ('dataset_path',\n",
       "              '/data_mil/datasets/postnauka/PostNauka_natural_order.csv'),\n",
       "             ('word', '@word'),\n",
       "             ('min_num_topics', 5),\n",
       "             ('max_num_topics', 50),\n",
       "             ('num_topics_interval', 3),\n",
       "             ('num_fit_iterations', 40),\n",
       "             ('num_restarts', 3)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['dataset_path'] = '/data/datasets/postnauka/PostNauka_natural_order.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PN'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"batches_prefix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    config['dataset_path'], \n",
    "    internals_folder_path=f'/home/alekseev/OptimalNumberOfTopics/demos/{config[\"batches_prefix\"]}_internals'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/datasets/postnauka/PostNauka_natural_order.csv'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num documents for coherence: 44, 23410 words\n"
     ]
    }
   ],
   "source": [
    "_ = build_every_score(dataset, dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DF_RATE = 0.01\n",
    "\n",
    "d = dataset.get_dictionary()\n",
    "\n",
    "d.filter(min_df_rate=MIN_DF_RATE)\n",
    "\n",
    "dataset._cached_dict = d\n",
    "\n",
    "train_dataset, test_dataset = split_into_train_test(dataset, config)\n",
    "\n",
    "train_dataset._cached_dict = train_dataset.get_dictionary().filter(min_df_rate=MIN_DF_RATE)\n",
    "test_dataset._cached_dict = test_dataset.get_dictionary().filter(min_df_rate=MIN_DF_RATE)\n",
    "\n",
    "text_collection = VowpalWabbitTextCollection.from_dataset(\n",
    "    train_dataset, main_modality=config['word']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.Dictionary(name=fb4abb1f-b336-4b30-970a-956aa723ee09, num_entries=5214)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_collection._to_dataset().get_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NG_20NG_NEW\t PN_PN_NEW\t      SO_SO_NEW\r\n",
      "Brown_Brown_NEW  Reuters_Reuters_NEW  WRef_NEW\r\n"
     ]
    }
   ],
   "source": [
    "! ls /data/_tmp_alekseev/OptNumExperiments/AllDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATASETS_FOLDER_PATH = '/data/_tmp_alekseev/OptNumExperiments/AllDatasets'\n",
    "DATASET_FOLDER_NAME = 'PN_PN_NEW'\n",
    "\n",
    "DATASET_FOLDER_PATH = os.path.join(\n",
    "    ALL_DATASETS_FOLDER_PATH,\n",
    "    DATASET_FOLDER_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PN_ARTM_0_0   PN_ARTM_3_0  PN_ARTM_8_0\t\t PN_LDA_0_0\tPN_sparse_1_0\r\n",
      "PN_ARTM_0_1   PN_ARTM_3_1  PN_ARTM_8_1\t\t PN_LDA_0_1\tPN_sparse_1_1\r\n",
      "PN_ARTM_0_2   PN_ARTM_3_2  PN_ARTM_8_2\t\t PN_LDA_0_2\tPN_sparse_1_2\r\n",
      "PN_ARTM_1_0   PN_ARTM_4_0  PN_ARTM_9_0\t\t PN_LDA_1_0\tPN_sparse_2_0\r\n",
      "PN_ARTM_10_0  PN_ARTM_4_1  PN_ARTM_9_1\t\t PN_LDA_1_1\tPN_sparse_2_1\r\n",
      "PN_ARTM_10_1  PN_ARTM_4_2  PN_ARTM_9_2\t\t PN_LDA_1_2\tPN_sparse_2_2\r\n",
      "PN_ARTM_10_2  PN_ARTM_5_0  PN_decorrelation_0_0  PN_LDA_2_0\tPN_sparse_3_0\r\n",
      "PN_ARTM_1_1   PN_ARTM_5_1  PN_decorrelation_0_1  PN_LDA_2_1\tPN_sparse_3_1\r\n",
      "PN_ARTM_11_0  PN_ARTM_5_2  PN_decorrelation_0_2  PN_LDA_2_2\tPN_sparse_3_2\r\n",
      "PN_ARTM_11_1  PN_ARTM_6_0  PN_decorrelation_1_0  PN_PLSA_0_0\tPN_TARTM_0_0\r\n",
      "PN_ARTM_11_2  PN_ARTM_6_1  PN_decorrelation_1_1  PN_PLSA_0_1\tPN_TARTM_0_1\r\n",
      "PN_ARTM_1_2   PN_ARTM_6_2  PN_decorrelation_1_2  PN_PLSA_0_2\tPN_TARTM_0_2\r\n",
      "PN_ARTM_2_0   PN_ARTM_7_0  PN_decorrelation_2_0  PN_sparse_0_0\r\n",
      "PN_ARTM_2_1   PN_ARTM_7_1  PN_decorrelation_2_1  PN_sparse_0_1\r\n",
      "PN_ARTM_2_2   PN_ARTM_7_2  PN_decorrelation_2_2  PN_sparse_0_2\r\n"
     ]
    }
   ],
   "source": [
    "! ls $DATASET_FOLDER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2563d7b9-bb6e-4607-8cb4-3ff4d2ee74f5  a42ff850-1d89-4d5f-a39d-d1be33286523\r\n",
      "29fdd77e-078b-4b9c-bcd9-9c335c9e0479  b8ba10bd-d642-4628-be84-00e713c886aa\r\n",
      "324ac57c-9be2-43c9-a403-1e444db066b0  b9e29ff5-d85f-48f2-93de-dd34355a1460\r\n",
      "42d74265-6669-4ddc-a771-e0095c4f6191  c389c2a7-56e8-44e5-86d2-f2da86de4cc6\r\n",
      "56ea63e6-82ac-4bce-a92d-71835367a980  ca8d1cf5-5b5f-49cb-92fc-61c03a51bb35\r\n",
      "88491c14-7780-45cd-987a-7360cb07cb5a  ddee9ad3-3c10-49f5-9cd4-cfe49d113dc3\r\n",
      "8ebd8257-bfa3-4edd-be89-7a00052df860  e58c2991-b630-4aa7-8943-2585ac26621b\r\n",
      "9ec8edee-9ca9-48ce-a379-2f41783d5149  fc36eff9-49d5-4b63-9596-d30883332fca\r\n"
     ]
    }
   ],
   "source": [
    "! ls $DATASET_FOLDER_PATH/PN_LDA_0_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_additional_scores() -> List[BaseScore]:\n",
    "    return [\n",
    "        HoldoutPerplexityScore(\n",
    "            name='new_holdout_perp',\n",
    "            test_dataset=test_dataset,\n",
    "        ),\n",
    "        MeanLiftScore(\n",
    "            name='lift',\n",
    "            validation_dataset=test_dataset,\n",
    "            modalities=[config['word']],\n",
    "        ),\n",
    "        UniformThetaDivergenceScore(\n",
    "            name='uni_theta_divergence',\n",
    "            validation_dataset=test_dataset,\n",
    "            modalities=[config['word']],\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_score_files(model_folder_path: str, scores: List[BaseScore]) -> None:\n",
    "    for f in os.listdir(model_folder_path):\n",
    "        if any(f.startswith(n + '.') for n in [s.name for s in scores]):\n",
    "            os.remove(os.path.join(model_folder_path, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_score(target_score: BaseScore, model: TopicModel) -> BaseTopicNetScore:\n",
    "    score_objects = list()\n",
    "\n",
    "    for score_name, score_object in model.custom_scores.items():\n",
    "        if score_name != target_score.name:\n",
    "            continue\n",
    "\n",
    "        score_objects.append(score_object)\n",
    "\n",
    "    assert len(score_objects) == 1\n",
    "\n",
    "    return score_objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_score(score: BaseTopicNetScore, score_name: str, model_folder_path: str) -> None:\n",
    "    class_name = score.__class__.__name__\n",
    "    save_path = os.path.join(\n",
    "        model_folder_path,\n",
    "        '.'.join([score_name, class_name, 'p'])\n",
    "    )\n",
    "\n",
    "    score.save(save_path)\n",
    "\n",
    "    saved_score = getattr(tn_scores, class_name).load(save_path)  # TODO: dirty\n",
    "\n",
    "    assert len(saved_score.value) == 1  # OptimalNumberOfTopics-specific check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for restart_folder_name in tqdm.tqdm(\n",
    "        os.listdir(DATASET_FOLDER_PATH)[:1],\n",
    "        total=len(os.listdir(DATASET_FOLDER_PATH)),\n",
    "        file=sys.stdout):\n",
    "\n",
    "    restart_folder_path = os.path.join(DATASET_FOLDER_PATH, restart_folder_name)\n",
    "    \n",
    "    for model_folder_name in os.listdir(restart_folder_path)[:1]:\n",
    "        model_folder_path = os.path.join(restart_folder_path, model_folder_name)\n",
    "\n",
    "        scores_to_compute = initialize_additional_scores()\n",
    "\n",
    "        delete_score_files(\n",
    "            model_folder_path=model_folder_path,\n",
    "            scores=scores_to_compute,\n",
    "        )\n",
    "        \n",
    "        model = TopicModel.load(model_folder_path)\n",
    "\n",
    "        for score in scores_to_compute:\n",
    "            score._attach(model)\n",
    "\n",
    "            score_object = find_score(score, model)\n",
    "\n",
    "            score_value = score_object.call(model)\n",
    "            score_object.update(score_value)  # TODO: carefully! this is kostyl kinda like\n",
    "\n",
    "            save_score(\n",
    "                score=score_object,\n",
    "                score_name=score.name,\n",
    "                model_folder_path=model_folder_path,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if all OK (for one model): what scores are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC_sparsity_False._LikelihoodBasedScore.p\r\n",
      "AIC_sparsity_True._LikelihoodBasedScore.p\r\n",
      "arun._SpectralDivergenceScore.p\r\n",
      "BIC_sparsity_False._LikelihoodBasedScore.p\r\n",
      "BIC_sparsity_True._LikelihoodBasedScore.p\r\n",
      "calhar._CalinskiHarabaszScore.p\r\n",
      "diversity_cosine_False._DiversityScore.p\r\n",
      "diversity_cosine_True._DiversityScore.p\r\n",
      "diversity_euclidean_False._DiversityScore.p\r\n",
      "diversity_euclidean_True._DiversityScore.p\r\n",
      "diversity_hellinger_False._DiversityScore.p\r\n",
      "diversity_hellinger_True._DiversityScore.p\r\n",
      "diversity_jensenshannon_False._DiversityScore.p\r\n",
      "diversity_jensenshannon_True._DiversityScore.p\r\n",
      "intra._IntratextCoherenceScore.p\r\n",
      "lift._MeanLiftScore.p\r\n",
      "MDL_sparsity_False._LikelihoodBasedScore.p\r\n",
      "MDL_sparsity_True._LikelihoodBasedScore.p\r\n",
      "model\r\n",
      "new_holdout_perp._HoldoutPerplexityScore.p\r\n",
      "params.json\r\n",
      "phi.csv\r\n",
      "renyi_0.5._RenyiShannonEntropyScore.p\r\n",
      "renyi_1._RenyiShannonEntropyScore.p\r\n",
      "renyi_2._RenyiShannonEntropyScore.p\r\n",
      "silh._SilhouetteScore.p\r\n",
      "toptok1._TopTokensCoherenceScore.p\r\n",
      "uni_theta_divergence._UniformThetaDivergenceScore.p\r\n"
     ]
    }
   ],
   "source": [
    "! ls $DATASET_FOLDER_PATH/PN_decorrelation_0_0/232c2a85-4893-43b8-9cea-9ead792eff8d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last model we worked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BIC_sparsity_False',\n",
       " 'BIC_sparsity_True',\n",
       " 'AIC_sparsity_True',\n",
       " 'calhar',\n",
       " 'intra',\n",
       " 'diversity_jensenshannon_True',\n",
       " 'diversity_cosine_True',\n",
       " 'MDL_sparsity_False',\n",
       " 'silh',\n",
       " 'diversity_cosine_False',\n",
       " 'renyi_1',\n",
       " 'arun',\n",
       " 'toptok1',\n",
       " 'diversity_euclidean_True',\n",
       " 'diversity_hellinger_True',\n",
       " 'renyi_0.5',\n",
       " 'renyi_2',\n",
       " 'diversity_hellinger_False',\n",
       " 'MDL_sparsity_True',\n",
       " 'AIC_sparsity_False',\n",
       " 'diversity_euclidean_False',\n",
       " 'diversity_jensenshannon_False',\n",
       " 'new_holdout_perp',\n",
       " 'lift',\n",
       " 'uni_theta_divergence']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.custom_scores.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topicnet",
   "language": "python",
   "name": "topicnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
